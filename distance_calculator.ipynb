{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3eeebc4-228c-4c39-b6b2-81312e950163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fb01697-65e0-4968-958c-824cc6e7e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_focal_length(known_distance, known_width, width_in_rf_image):\n",
    "    return (width_in_rf_image * known_distance) / known_width\n",
    "\n",
    "def calculate_distance(focal_length, known_width, width_in_frame):\n",
    "    return (known_width * focal_length) / width_in_frame\n",
    "\n",
    "def capture_card_template():\n",
    "    print(\"Align the card within the box and press 'c' to capture the card template.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Draw a guide frame on the screen\n",
    "        height, width, _ = frame.shape\n",
    "        cv2.rectangle(frame, (int(width*0.3), int(height*0.3)), (int(width*0.7), int(height*0.7)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Press 'c' to capture card template\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Capture Card Template', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('c'):\n",
    "            # Capture the template\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Crop the region inside the guide frame\n",
    "            card_template = gray_frame[int(height*0.3):int(height*0.7), int(width*0.3):int(width*0.7)]\n",
    "            cv2.destroyWindow('Capture Card Template')\n",
    "            return card_template\n",
    "\n",
    "def detect_card_with_template(frame, template):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Ensure the template is smaller than the frame\n",
    "    if template.shape[0] > gray_frame.shape[0] or template.shape[1] > gray_frame.shape[1]:\n",
    "        raise ValueError(\"Template image is larger than the frame. Resize the template.\")\n",
    "\n",
    "    result = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, max_val, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    if max_val > 0.7:  # Threshold to consider it a match\n",
    "        (tH, tW) = template.shape[:2]\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + tW, top_left[1] + tH)\n",
    "        cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        return tW  # Return the width of the template in pixels\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef79570b-d379-4fac-9958-b41d47ce59b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align the card within the box and press 'c' to capture the card template.\n",
      "Please hold the card in front of the camera as before, and align it within the frame box.\n",
      "Calibration complete. Focal Length calculated: 768.00 pixels.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "KNOWN_WIDTH_OBJ = 8.5  # Known width of the reference object (e.g., credit card in cm)\n",
    "KNOWN_DISTANCE = 25.5  # Calibration distance (in cm)\n",
    "ALERT_DISTANCE = 50.0  # Distance threshold for alert (in cm)\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture the card template during the calibration step\n",
    "card_template = capture_card_template()\n",
    "\n",
    "# Calibration step\n",
    "print(\"Please hold the card in front of the camera as before, and align it within the frame box.\")\n",
    "\n",
    "calibrated = False\n",
    "focal_length = None\n",
    "\n",
    "while not calibrated:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Draw a guide frame on the screen\n",
    "    height, width, _ = frame.shape\n",
    "    cv2.rectangle(frame, (int(width*0.3), int(height*0.3)), (int(width*0.7), int(height*0.7)), (0, 255, 0), 2)\n",
    "    cv2.putText(frame, \"Press 'c' to calibrate\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Calibration', frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('c'):  # Press 'c' to calibrate\n",
    "        object_width_in_frame = detect_card_with_template(frame, card_template)\n",
    "        \n",
    "        if object_width_in_frame:\n",
    "            # Calculate the focal length using the width of the detected card\n",
    "            focal_length = calculate_focal_length(KNOWN_DISTANCE, KNOWN_WIDTH_OBJ, object_width_in_frame)\n",
    "            print(f\"Calibration complete. Focal Length calculated: {focal_length:.2f} pixels.\")\n",
    "            calibrated = True\n",
    "        else:\n",
    "            print(\"Object not detected. Please ensure the card is visible and try again.\")\n",
    "    \n",
    "    if key == ord('q'):  # Press 'q' to quit calibration\n",
    "        print(\"Calibration aborted.\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        exit()\n",
    "\n",
    "cv2.destroyWindow('Calibration')  # Close the calibration window\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        #print(\"Face Width\",w)  ##################################################\n",
    "        distance = calculate_distance(focal_length, KNOWN_WIDTH_OBJ, w)\n",
    "\n",
    "        # Display the distance on the frame\n",
    "        cv2.putText(frame, f\"Distance: {distance:.2f} cm\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Check if the distance exceeds the alert threshold\n",
    "        if distance > ALERT_DISTANCE:\n",
    "            cv2.putText(frame, \"Alert: User left the desk!\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Distance Monitor', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2696f218-47f0-465f-ab91-5d1e928f6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "focal_length = 768.0\n",
    "KNOWN_WIDTH_OBJ = 8.5  # Known width of the reference object (e.g., credit card in cm)\n",
    "KNOWN_DISTANCE = 25.5  # Calibration distance (in cm)\n",
    "ALERT_DISTANCE = 50.0  # Distance threshold for alert (in cm)\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        #print(\"Face Width\",w)  ##################################################\n",
    "        distance = calculate_distance(focal_length, KNOWN_WIDTH_OBJ, w)\n",
    "\n",
    "        # Display the distance on the frame\n",
    "        cv2.putText(frame, f\"Distance: {distance:.2f} cm\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Check if the distance exceeds the alert threshold\n",
    "        if distance > ALERT_DISTANCE:\n",
    "            cv2.putText(frame, \"Alert: User left the desk!\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Distance Monitor', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "303cdbd7-b9fa-428e-8af9-50e5ec65b913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 face(s)\n",
      "Face encoding successful.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "image = face_recognition.load_image_file(\"Downloads/EMS_desk/desk1/WIN_20240729_18_29_33_Pro.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "print(f\"Detected {len(face_encodings)} face(s)\")\n",
    "\n",
    "# Display the result for debugging\n",
    "if len(face_encodings) > 0:\n",
    "    print(\"Face encoding successful.\")\n",
    "else:\n",
    "    print(\"No faces detected or encoding failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5eecf-ea8a-4851-a081-efab2ded6bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e435c-2041-4e95-a3e5-a803a2d1d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                ## HUMAN TRIALS ## BEWARE ## DANGER ## BEWARE ## HUMAN TRIALS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2997851-a5e0-4391-b3ca-7ab387c9b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calculate_focal_length(known_distance, known_width, width_in_rf_image):\n",
    "    return (width_in_rf_image * known_distance) / known_width\n",
    "\n",
    "def calculate_distance(focal_length, known_width, width_in_frame):\n",
    "    return (known_width * focal_length) / width_in_frame\n",
    "\n",
    "def capture_face_template():\n",
    "    print(\"Align your face within the oval and press 'c' to capture the face template.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        center = (int(width * 0.5), int(height * 0.5))\n",
    "        axes = (int(width * 0.2), int(height * 0.3))  # Ellipse axes lengths\n",
    "        \n",
    "        # Draw an oval guide on the screen\n",
    "        cv2.ellipse(frame, center, axes, 0, 0, 360, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Press 'c' to capture face template\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Capture Face Template', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('c'):\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            face_template = gray_frame[center[1] - axes[1]:center[1] + axes[1], center[0] - axes[0]:center[0] + axes[0]]\n",
    "            cv2.destroyWindow('Capture Face Template')\n",
    "            return face_template\n",
    "\n",
    "def detect_face_with_template(frame, template):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if template.shape[0] > gray_frame.shape[0] or template.shape[1] > gray_frame.shape[1]:\n",
    "        raise ValueError(\"Template image is larger than the frame. Resize the template.\")\n",
    "\n",
    "    result = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, max_val, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    if max_val > 0.7:\n",
    "        (tH, tW) = template.shape[:2]\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + tW, top_left[1] + tH)\n",
    "        cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        return tW\n",
    "    return None\n",
    "\n",
    "\n",
    "KNOWN_WIDTH_OBJ = 15.0  # Known width of the human face in cm\n",
    "KNOWN_DISTANCE = 40.0\n",
    "ALERT_DISTANCE = 50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74b561b7-5f9e-428f-99ef-966ece7914ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align your face within the oval and press 'c' to capture the face template.\n",
      "Please align your face within the oval and press 'c' to calibrate.\n",
      "Calibration complete. Focal Length calculated: 682.67 pixels.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Replace the card calibration with face calibration\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_template = capture_face_template()\n",
    "\n",
    "print(\"Please align your face within the oval and press 'c' to calibrate.\")\n",
    "\n",
    "calibrated = False\n",
    "focal_length = None\n",
    "\n",
    "while not calibrated:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    height, width, _ = frame.shape\n",
    "    center = (int(width * 0.5), int(height * 0.5))\n",
    "    axes = (int(width * 0.2), int(height * 0.3))\n",
    "    cv2.ellipse(frame, center, axes, 0, 0, 360, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, \"Press 'c' to calibrate\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Calibration', frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('c'):\n",
    "        face_width_in_frame = detect_face_with_template(frame, face_template)\n",
    "        \n",
    "        if face_width_in_frame:\n",
    "            focal_length = calculate_focal_length(KNOWN_DISTANCE, KNOWN_WIDTH_OBJ, face_width_in_frame)\n",
    "            print(f\"Calibration complete. Focal Length calculated: {focal_length:.2f} pixels.\")\n",
    "            calibrated = True\n",
    "        else:\n",
    "            print(\"Face not detected. Please ensure your face is visible and try again.\")\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        print(\"Calibration aborted.\")\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        exit()\n",
    "\n",
    "cv2.destroyWindow('Calibration')\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7816a606-02f0-4866-aa2c-0f1fe6a06b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_start_time = None\n",
    "focal_length = 682.67\n",
    "ALERT_DISTANCE = 70.0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        distance = calculate_distance(focal_length, KNOWN_WIDTH_OBJ, w)\n",
    "\n",
    "        cv2.putText(frame, f\"Distance: {distance:.2f} cm\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        if distance > ALERT_DISTANCE:\n",
    "            if alert_start_time is None:\n",
    "                alert_start_time = time.time()  # Start timing when distance exceeds the threshold\n",
    "            elif time.time() - alert_start_time > 5:  # Check if 1 minute has passed\n",
    "                cv2.putText(frame, \"Alert: User left the desk!\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            alert_start_time = None  # Reset timer if the user moves back within the distance\n",
    "\n",
    "    cv2.imshow('Distance Monitor', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e19041ea-72f5-47b4-8ae8-8fa46f63f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68016b6-4549-4a20-9af2-6821d0ee02f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddcd23b8-06ca-44ba-b031-405e66db85b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align your face within the oval and press 'c' to capture the face template.\n",
      "Please align your face within the oval and press 'c' to calibrate.\n",
      "Calibration complete. Focal Length calculated: 682.67 pixels.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calculate_focal_length(known_distance, known_width, width_in_rf_image):\n",
    "    return (width_in_rf_image * known_distance) / known_width\n",
    "\n",
    "def calculate_distance(focal_length, known_width, width_in_frame):\n",
    "    return (known_width * focal_length) / width_in_frame\n",
    "\n",
    "def capture_face_template(cap):\n",
    "    print(\"Align your face within the oval and press 'c' to capture the face template.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        center = (int(width * 0.5), int(height * 0.5))\n",
    "        axes = (int(width * 0.2), int(height * 0.3))  # Ellipse axes lengths\n",
    "        \n",
    "        cv2.ellipse(frame, center, axes, 0, 0, 360, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Press 'c' to capture face template\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Capture Face Template', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('c'):\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            face_template = gray_frame[center[1] - axes[1]:center[1] + axes[1], center[0] - axes[0]:center[0] + axes[0]]\n",
    "            cv2.destroyWindow('Capture Face Template')\n",
    "            return face_template\n",
    "\n",
    "def detect_face_with_template(frame, template):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if template.shape[0] > gray_frame.shape[0] or template.shape[1] > gray_frame.shape[1]:\n",
    "        raise ValueError(\"Template image is larger than the frame. Resize the template.\")\n",
    "\n",
    "    result = cv2.matchTemplate(gray_frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    _, max_val, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    if max_val > 0.7:\n",
    "        (tH, tW) = template.shape[:2]\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + tW, top_left[1] + tH)\n",
    "        cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        return tW\n",
    "    return None\n",
    "\n",
    "def calibrate_focal_length(cap, known_distance, known_width_obj, face_template):\n",
    "    print(\"Please align your face within the oval and press 'c' to calibrate.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        center = (int(width * 0.5), int(height * 0.5))\n",
    "        axes = (int(width * 0.2), int(height * 0.3))\n",
    "        cv2.ellipse(frame, center, axes, 0, 0, 360, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Press 'c' to calibrate\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Calibration', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('c'):\n",
    "            face_width_in_frame = detect_face_with_template(frame, face_template)\n",
    "            \n",
    "            if face_width_in_frame:\n",
    "                focal_length = calculate_focal_length(known_distance, known_width_obj, face_width_in_frame)\n",
    "                print(f\"Calibration complete. Focal Length calculated: {focal_length:.2f} pixels.\")\n",
    "                cv2.destroyWindow('Calibration')\n",
    "                return focal_length\n",
    "            else:\n",
    "                print(\"Face not detected. Please ensure your face is visible and try again.\")\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            print(\"Calibration aborted.\")\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            exit()\n",
    "\n",
    "def monitor_distance(cap, focal_length, known_width_obj, alert_distance):\n",
    "    alert_start_time = None\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml').detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            (x, y, w, h) = faces[0]\n",
    "            distance = calculate_distance(focal_length, known_width_obj, w)\n",
    "\n",
    "            cv2.putText(frame, f\"Distance: {distance:.2f} cm\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            if distance > alert_distance:\n",
    "                if alert_start_time is None:\n",
    "                    alert_start_time = time.time()  # Start timing when distance exceeds the threshold\n",
    "                elif time.time() - alert_start_time > 5:  # Check if 5 seconds have passed\n",
    "                    cv2.putText(frame, \"Alert: User left the desk!\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            else:\n",
    "                alert_start_time = None  # Reset timer if the user moves back within the distance\n",
    "\n",
    "        cv2.imshow('Distance Monitor', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "def main():\n",
    "    KNOWN_WIDTH_OBJ = 15.0  # Known width of the human face in cm\n",
    "    KNOWN_DISTANCE = 40.0\n",
    "    ALERT_DISTANCE = 70.0\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    face_template = capture_face_template(cap)\n",
    "    \n",
    "    focal_length = calibrate_focal_length(cap, KNOWN_DISTANCE, KNOWN_WIDTH_OBJ, face_template)\n",
    "    \n",
    "    # Set up a new capture for monitoring\n",
    "    cap.release()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    monitor_distance(cap, focal_length, KNOWN_WIDTH_OBJ, ALERT_DISTANCE)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215602e-3a9f-461e-b009-1aa010a80d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
